{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos el problema de difusión:\n",
    "\n",
    "$$-\\phi_{xx}=0 \\hspace{0.8em} (t,x) \\in (0,1) \\times (0,2)$$\n",
    "$$\\phi(t,0)=0; \\phi(t,1)=1 \\hspace{0.8em} t \\in (0,1)$$\n",
    "$$\\phi(0,x) = \\sigma(M(x-1/2))$$\n",
    "\n",
    "Consideramos $c=1$ en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto no converge, he visto que se utilizan redes neurales de prueba es decir reducir el numero de parámetros o modificar la arquitectura.\n",
    "\n",
    "https://arxiv.org/pdf/2104.05512.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 19:54:10.657625: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 19:54:10.657689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 19:54:10.659686: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 19:54:10.672685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 19:54:12.347679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "DTYPE='float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(num_hidden_layers=8, num_neurons_per_layer=20, add_last_layer=1):\n",
    "    # Initialize a feedforward neural network\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Input is two-dimensional (time + one spatial dimension)\n",
    "    model.add(tf.keras.Input([2]))\n",
    "\n",
    "    # Introduce a scaling layer to map input to [lb, ub]\n",
    "    #scaling_layer = tf.keras.layers.Lambda(\n",
    "    #            lambda x: 2.0*(x - lb)/(ub - lb) - 1.0)\n",
    "    #model.add(scaling_layer)\n",
    "\n",
    "    # Append hidden layers\n",
    "    for _ in range(num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(num_neurons_per_layer,\n",
    "            activation=\"sigmoid\", use_bias=True))\n",
    "\n",
    "    # Output is one-dimensional\n",
    "    if(add_last_layer):\n",
    "        model.add(tf.keras.layers.Dense(1, activation=None))\n",
    "        \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(model, X_r):\n",
    "\n",
    "    # A tf.GradientTape is used to compute derivatives in TensorFlow\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Split t and x to compute partial derivatives\n",
    "        x, y = X_r[:, 0:1], X_r[:,1:2]\n",
    "        # Variables t and x are watched during tape\n",
    "        # to compute derivatives u_t and u_x\n",
    "        tape.watch(x)\n",
    "        tape.watch(y)\n",
    "\n",
    "        # Determine residual\n",
    "        u = model(tf.stack([x[:,0], y[:,0]], axis=1))\n",
    "\n",
    "        # Compute gradient u_x within the GradientTape\n",
    "        # since we need second derivatives\n",
    "        u_x = tape.gradient(u, x)\n",
    "        u_y = tape.gradient(u, y)\n",
    "\n",
    "    u_xx = tape.gradient(u_x, x)\n",
    "    u_yy = tape.gradient(u_y, y)\n",
    "\n",
    "    del tape\n",
    "\n",
    "    return fun_r(x,u_x,u_y,u_xx,u_yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry(x):\n",
    "    aux = x.numpy()\n",
    "\n",
    "    aux[:, 1] = 2\n",
    "    return tf.convert_to_tensor(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, X_r, periodic_points_1, periodic_points_2, t0_points):\n",
    "\n",
    "    # Compute phi^r\n",
    "    r  = get_gradient(model, X_r)\n",
    "    phi_r = tf.reduce_mean(tf.square(r))\n",
    "\n",
    "    # Initialize loss\n",
    "    loss_XR = phi_r\n",
    "    \n",
    "    # Periodic \n",
    "    \n",
    "    loss_boundary = tf.reduce_mean(tf.square(model(periodic_points_1)- 0))\n",
    "    loss_boundary += tf.reduce_mean(tf.square(model(periodic_points_1)- 1))\n",
    "    # TN Point DUDAS\n",
    "    \n",
    "    loss_T0 = tf.reduce_mean(tf.square(model(t0_points)-eval))\n",
    "    \n",
    "    #x, y, u_x, u_y, u_xx, u_yy = get_gradient(model, tn_points)\n",
    "    #tn_error=tf.pow(tf.square(u_x)+ tf.square(u_y), 1/2)-g(x,y)\n",
    "    #tn_error=tf.reduce_sum(tf.square(tn_error), axis=0)\n",
    "    #loss += tn_error\n",
    "    loss = loss_XR + loss_boundary+loss_T0\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(model, X_r, td_points_1, td_points_2, tn_points):\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # This tape is for derivatives with\n",
    "        # respect to trainable variables\n",
    "        tape.watch(model.trainable_variables)\n",
    "        loss = compute_loss(model, X_r, td_points_1, td_points_2, tn_points)\n",
    "\n",
    "    g = tape.gradient(loss, model.trainable_variables)\n",
    "    del tape\n",
    "    \n",
    "    return loss, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def train(mlp):\n",
    "    # Define one training step as a TensorFlow function to increase speed of training\n",
    "    @tf.function\n",
    "    def train_step():\n",
    "        # Compute current loss and gradient w.r.t. parameters\n",
    "        loss, grad_theta = get_grad(mlp, X_r, bound_points_1, bound_points_2, t0_points)\n",
    "\n",
    "        # Perform gradient descent step\n",
    "        optim.apply_gradients(zip(grad_theta, mlp.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Number of training epochs\n",
    "    N = 20000\n",
    "    hist = []\n",
    "\n",
    "    # Start timer\n",
    "    t0 = time()\n",
    "\n",
    "    for i in range(N+1):\n",
    "\n",
    "        loss = train_step()\n",
    "\n",
    "        # Append current loss to hist\n",
    "        hist.append(loss.numpy())\n",
    "\n",
    "        # Output current loss after 50 iterates\n",
    "        if i%50 == 0:\n",
    "            print('It {:05d}'.format(i))\n",
    "            print('loss: ', loss.numpy())\n",
    "\n",
    "    # Print computation time\n",
    "    print('\\nComputation time: {} seconds'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Condition\n",
    "\n",
    "\n",
    "C=1000\n",
    "def f(x):\n",
    "    return 1/(1+np.exp(-C*(x-1/2)))\n",
    "\n",
    "\n",
    "C=700\n",
    "def exact_sol(m):\n",
    "    return 0*m\n",
    "\n",
    "\n",
    "'''\n",
    "def f(x):\n",
    "    # Perform the comparison\n",
    "    comparison = tf.logical_and(tf.greater(x, 1/3), tf.less(x, 2/3))\n",
    "\n",
    "    # Convert boolean values to integers (1 for True, 0 for False)\n",
    "    result = tf.cast(comparison, tf.float32)\n",
    "    return result\n",
    "\n",
    "def exact_sol(m):\n",
    "    result = []\n",
    "    for value in m:\n",
    "        if 1/3 < value < 2/3:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result\n",
    "'''\n",
    "\n",
    "# Condition for the equation\n",
    "c=1\n",
    "def fun_r(x, u_x, u_t, u_xx, u_tt):\n",
    "    return -u_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Number of Data points\n",
    "N_t0=1000 # For initial condition\n",
    "N_periodic=1000 # For periodic Condition\n",
    "N_r=3000 # For Random points inside the domain\n",
    "\n",
    "# Rectangular domain for which we are solving\n",
    "xmin=0\n",
    "xmax=2\n",
    "tmin=0\n",
    "tmax=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexpf/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460: RuntimeWarning: overflow encountered in exp\n",
      "  return f(*args)\n"
     ]
    }
   ],
   "source": [
    "# Creation of points\n",
    "\n",
    "# Lower bounds\n",
    "lb = tf.constant([xmin, tmin], dtype=DTYPE)\n",
    "# Upper bounds\n",
    "ub = tf.constant([xmax, tmax], dtype=DTYPE)\n",
    "\n",
    "# Draw uniformly sampled collocation points\n",
    "x_r = tf.random.uniform((N_r,1), lb[0], ub[0], dtype=DTYPE)\n",
    "y_r = tf.random.uniform((N_r,1), lb[1], ub[1], dtype=DTYPE)\n",
    "\n",
    "X_r = tf.concat([x_r, y_r], axis=1)\n",
    "\n",
    "# t0\n",
    "aux = tf.random.uniform((N_t0,1), lb[0], ub[0], dtype=DTYPE)\n",
    "aux1 = tf.ones((N_t0, 1), dtype=DTYPE)*lb[0]\n",
    "\n",
    "eval = tf.map_fn(f, aux)\n",
    "t0_points=tf.concat([aux1, aux], axis=1)\n",
    "\n",
    "\n",
    "# boundary\n",
    "aux = tf.random.uniform((N_periodic,1), lb[1], ub[1], dtype=DTYPE)\n",
    "aux1 = tf.ones((N_periodic, 1), dtype=DTYPE)*lb[0]\n",
    "bound_points_1 = tf.concat([aux, aux1], axis=1)\n",
    "\n",
    "aux = tf.random.uniform((N_periodic,1), lb[1], ub[1], dtype=DTYPE)\n",
    "aux1 = tf.ones((N_periodic, 1), dtype=DTYPE)*lb[0]\n",
    "bound_points_2 = tf.concat([aux, aux1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291 (1.14 KB)\n",
      "Trainable params: 291 (1.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "It 00000\n",
      "loss:  2.178543\n",
      "It 00050\n",
      "loss:  0.7288206\n",
      "It 00100\n",
      "loss:  0.7273981\n",
      "It 00150\n",
      "loss:  0.7273882\n",
      "It 00200\n",
      "loss:  0.72738796\n",
      "It 00250\n",
      "loss:  0.72738796\n",
      "It 00300\n",
      "loss:  0.727388\n",
      "It 00350\n",
      "loss:  0.7273883\n",
      "It 00400\n",
      "loss:  0.7273879\n",
      "It 00450\n",
      "loss:  0.727388\n",
      "It 00500\n",
      "loss:  0.7273879\n",
      "It 00550\n",
      "loss:  0.7273879\n",
      "It 00600\n",
      "loss:  0.727388\n",
      "It 00650\n",
      "loss:  0.72738796\n",
      "It 00700\n",
      "loss:  0.7273882\n",
      "It 00750\n",
      "loss:  0.7273881\n",
      "It 00800\n",
      "loss:  0.727388\n",
      "It 00850\n",
      "loss:  0.72738796\n",
      "It 00900\n",
      "loss:  0.727388\n",
      "It 00950\n",
      "loss:  0.72738826\n",
      "It 01000\n",
      "loss:  0.727388\n",
      "It 01050\n",
      "loss:  0.7273879\n",
      "It 01100\n",
      "loss:  0.7273881\n",
      "It 01150\n",
      "loss:  0.7273882\n",
      "It 01200\n",
      "loss:  0.72738796\n",
      "It 01250\n",
      "loss:  0.72738814\n",
      "It 01300\n",
      "loss:  0.7273881\n",
      "It 01350\n",
      "loss:  0.72738814\n",
      "It 01400\n",
      "loss:  0.72738814\n",
      "It 01450\n",
      "loss:  0.7273883\n",
      "It 01500\n",
      "loss:  0.72738814\n",
      "It 01550\n",
      "loss:  0.727388\n",
      "It 01600\n",
      "loss:  0.727388\n",
      "It 01650\n",
      "loss:  0.72738814\n",
      "It 01700\n",
      "loss:  0.72738814\n",
      "It 01750\n",
      "loss:  0.727388\n",
      "It 01800\n",
      "loss:  0.72738814\n",
      "It 01850\n",
      "loss:  0.7273881\n",
      "It 01900\n",
      "loss:  0.7273881\n",
      "It 01950\n",
      "loss:  0.72738814\n",
      "It 02000\n",
      "loss:  0.727388\n",
      "It 02050\n",
      "loss:  0.72738814\n",
      "It 02100\n",
      "loss:  0.72738814\n",
      "It 02150\n",
      "loss:  0.72738814\n",
      "It 02200\n",
      "loss:  0.72738814\n",
      "It 02250\n",
      "loss:  0.72738814\n",
      "It 02300\n",
      "loss:  0.72738814\n",
      "It 02350\n",
      "loss:  0.72738796\n",
      "It 02400\n",
      "loss:  0.727388\n",
      "It 02450\n",
      "loss:  0.72738796\n",
      "It 02500\n",
      "loss:  0.72738814\n",
      "It 02550\n",
      "loss:  0.72738796\n",
      "It 02600\n",
      "loss:  0.72738826\n",
      "It 02650\n",
      "loss:  0.72738796\n",
      "It 02700\n",
      "loss:  0.7273879\n",
      "It 02750\n",
      "loss:  0.7273881\n",
      "It 02800\n",
      "loss:  0.727388\n",
      "It 02850\n",
      "loss:  0.7273879\n",
      "It 02900\n",
      "loss:  0.72738796\n",
      "It 02950\n",
      "loss:  0.72738814\n",
      "It 03000\n",
      "loss:  0.7273879\n",
      "It 03050\n",
      "loss:  0.7273882\n",
      "It 03100\n",
      "loss:  0.727388\n",
      "It 03150\n",
      "loss:  0.7273879\n",
      "It 03200\n",
      "loss:  0.72738814\n",
      "It 03250\n",
      "loss:  0.72738814\n",
      "It 03300\n",
      "loss:  0.727388\n",
      "It 03350\n",
      "loss:  0.72738814\n",
      "It 03400\n",
      "loss:  0.7273881\n",
      "It 03450\n",
      "loss:  0.7273881\n",
      "It 03500\n",
      "loss:  0.7273882\n",
      "It 03550\n",
      "loss:  0.7273881\n",
      "It 03600\n",
      "loss:  0.7273879\n",
      "It 03650\n",
      "loss:  0.7273883\n",
      "It 03700\n",
      "loss:  0.72738814\n",
      "It 03750\n",
      "loss:  0.7273879\n",
      "It 03800\n",
      "loss:  0.7273881\n",
      "It 03850\n",
      "loss:  0.7273879\n",
      "It 03900\n",
      "loss:  0.72738814\n",
      "It 03950\n",
      "loss:  0.7273879\n",
      "It 04000\n",
      "loss:  0.72738814\n",
      "It 04050\n",
      "loss:  0.727388\n",
      "It 04100\n",
      "loss:  0.727388\n",
      "It 04150\n",
      "loss:  0.7273891\n",
      "It 04200\n",
      "loss:  0.72738814\n",
      "It 04250\n",
      "loss:  0.72739357\n",
      "It 04300\n",
      "loss:  0.7273882\n",
      "It 04350\n",
      "loss:  0.7273895\n",
      "It 04400\n",
      "loss:  0.7283287\n",
      "It 04450\n",
      "loss:  0.72738874\n",
      "It 04500\n",
      "loss:  0.7273882\n",
      "It 04550\n",
      "loss:  0.72754085\n",
      "It 04600\n",
      "loss:  0.7274053\n",
      "It 04650\n",
      "loss:  0.7273888\n",
      "It 04700\n",
      "loss:  0.7273879\n",
      "It 04750\n",
      "loss:  0.7274387\n",
      "It 04800\n",
      "loss:  0.7274141\n",
      "It 04850\n",
      "loss:  0.7273882\n",
      "It 04900\n",
      "loss:  0.72738785\n",
      "It 04950\n",
      "loss:  0.7273904\n",
      "It 05000\n",
      "loss:  0.72759473\n",
      "It 05050\n",
      "loss:  0.727389\n",
      "It 05100\n",
      "loss:  0.72738826\n",
      "It 05150\n",
      "loss:  0.7273906\n",
      "It 05200\n",
      "loss:  0.7278879\n",
      "It 05250\n",
      "loss:  0.7273891\n",
      "It 05300\n",
      "loss:  0.7273882\n",
      "It 05350\n",
      "loss:  0.7273884\n",
      "It 05400\n",
      "loss:  0.7276716\n",
      "It 05450\n",
      "loss:  0.7273965\n",
      "It 05500\n",
      "loss:  0.72738826\n",
      "It 05550\n",
      "loss:  0.7274541\n",
      "It 05600\n",
      "loss:  0.727656\n",
      "It 05650\n",
      "loss:  0.7273881\n",
      "It 05700\n",
      "loss:  0.7273882\n",
      "It 05750\n",
      "loss:  0.73397624\n",
      "It 05800\n",
      "loss:  0.7273882\n",
      "It 05850\n",
      "loss:  0.7273883\n",
      "It 05900\n",
      "loss:  0.7273881\n",
      "It 05950\n",
      "loss:  0.727696\n",
      "It 06000\n",
      "loss:  0.72741264\n",
      "It 06050\n",
      "loss:  0.7273883\n",
      "It 06100\n",
      "loss:  0.72738814\n",
      "It 06150\n",
      "loss:  0.72738814\n",
      "It 06200\n",
      "loss:  0.7283632\n",
      "It 06250\n",
      "loss:  0.72740716\n",
      "It 06300\n",
      "loss:  0.72738796\n",
      "It 06350\n",
      "loss:  0.72738796\n",
      "It 06400\n",
      "loss:  0.737492\n",
      "It 06450\n",
      "loss:  0.72742623\n",
      "It 06500\n",
      "loss:  0.7273885\n",
      "It 06550\n",
      "loss:  0.7273894\n",
      "It 06600\n",
      "loss:  0.7285675\n",
      "It 06650\n",
      "loss:  0.7273961\n",
      "It 06700\n",
      "loss:  0.72738796\n",
      "It 06750\n",
      "loss:  0.72778\n",
      "It 06800\n",
      "loss:  0.7274003\n",
      "It 06850\n",
      "loss:  0.7273882\n",
      "It 06900\n",
      "loss:  0.7273886\n",
      "It 06950\n",
      "loss:  0.7291108\n",
      "It 07000\n",
      "loss:  0.72738814\n",
      "It 07050\n",
      "loss:  0.72738826\n",
      "It 07100\n",
      "loss:  0.72740424\n",
      "It 07150\n",
      "loss:  0.7273926\n",
      "It 07200\n",
      "loss:  0.72738796\n",
      "It 07250\n",
      "loss:  0.7273881\n",
      "It 07300\n",
      "loss:  0.7273881\n",
      "It 07350\n",
      "loss:  0.7391063\n",
      "It 07400\n",
      "loss:  0.72741663\n",
      "It 07450\n",
      "loss:  0.7273883\n",
      "It 07500\n",
      "loss:  0.72738814\n",
      "It 07550\n",
      "loss:  0.73973435\n",
      "It 07600\n",
      "loss:  0.7274508\n",
      "It 07650\n",
      "loss:  0.7273887\n",
      "It 07700\n",
      "loss:  0.72738826\n",
      "It 07750\n",
      "loss:  0.7274066\n",
      "It 07800\n",
      "loss:  0.7274915\n",
      "It 07850\n",
      "loss:  0.7273879\n",
      "It 07900\n",
      "loss:  0.727388\n",
      "It 07950\n",
      "loss:  0.72740006\n",
      "It 08000\n",
      "loss:  0.7276636\n",
      "It 08050\n",
      "loss:  0.727391\n",
      "It 08100\n",
      "loss:  0.7273881\n",
      "It 08150\n",
      "loss:  0.7273887\n",
      "It 08200\n",
      "loss:  0.7286265\n",
      "It 08250\n",
      "loss:  0.7273901\n",
      "It 08300\n",
      "loss:  0.727388\n",
      "It 08350\n",
      "loss:  0.7273886\n",
      "It 08400\n",
      "loss:  0.7277255\n",
      "It 08450\n",
      "loss:  0.7273954\n",
      "It 08500\n",
      "loss:  0.72738796\n",
      "It 08550\n",
      "loss:  0.727388\n",
      "It 08600\n",
      "loss:  0.72837734\n",
      "It 08650\n",
      "loss:  0.7273907\n",
      "It 08700\n",
      "loss:  0.72738826\n",
      "It 08750\n",
      "loss:  0.7273881\n",
      "It 08800\n",
      "loss:  0.7278987\n",
      "It 08850\n",
      "loss:  0.7275841\n",
      "It 08900\n",
      "loss:  0.72738874\n",
      "It 08950\n",
      "loss:  0.7273881\n",
      "It 09000\n",
      "loss:  0.7273881\n",
      "It 09050\n",
      "loss:  0.7273888\n",
      "It 09100\n",
      "loss:  0.7283213\n",
      "It 09150\n",
      "loss:  0.7273891\n",
      "It 09200\n",
      "loss:  0.7273881\n",
      "It 09250\n",
      "loss:  0.727388\n",
      "It 09300\n",
      "loss:  0.72738814\n",
      "It 09350\n",
      "loss:  0.72739255\n",
      "It 09400\n",
      "loss:  0.7274095\n",
      "It 09450\n",
      "loss:  0.7273884\n",
      "It 09500\n",
      "loss:  0.72738826\n",
      "It 09550\n",
      "loss:  0.7273879\n",
      "It 09600\n",
      "loss:  0.7273882\n",
      "It 09650\n",
      "loss:  0.7275985\n",
      "It 09700\n",
      "loss:  0.727393\n",
      "It 09750\n",
      "loss:  0.72738826\n",
      "It 09800\n",
      "loss:  0.727388\n",
      "It 09850\n",
      "loss:  0.7296313\n",
      "It 09900\n",
      "loss:  0.7274902\n",
      "It 09950\n",
      "loss:  0.7273884\n",
      "It 10000\n",
      "loss:  0.727388\n",
      "It 10050\n",
      "loss:  0.7273882\n",
      "It 10100\n",
      "loss:  0.72815275\n",
      "It 10150\n",
      "loss:  0.7273901\n",
      "It 10200\n",
      "loss:  0.72738814\n",
      "It 10250\n",
      "loss:  0.7273961\n",
      "It 10300\n",
      "loss:  0.72762007\n",
      "It 10350\n",
      "loss:  0.7273916\n",
      "It 10400\n",
      "loss:  0.72738814\n",
      "It 10450\n",
      "loss:  0.7282898\n",
      "It 10500\n",
      "loss:  0.72740185\n",
      "It 10550\n",
      "loss:  0.7273882\n",
      "It 10600\n",
      "loss:  0.7273886\n",
      "It 10650\n",
      "loss:  0.72872317\n",
      "It 10700\n",
      "loss:  0.7273886\n",
      "It 10750\n",
      "loss:  0.727388\n",
      "It 10800\n",
      "loss:  0.72738785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mlp \u001b[38;5;241m=\u001b[39m init_model(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m optim\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(mlp)\u001b[0m\n\u001b[1;32m     20\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Append current loss to hist\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     hist\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Projects/ED-Solve/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp = init_model(10, 5)\n",
    "optim=tf.keras.optimizers.Adam(learning_rate=0.5)\n",
    "\n",
    "train(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9 (36.00 Byte)\n",
      "Trainable params: 9 (36.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_summary(mlp):\n",
    "    t0=0\n",
    "    x=np.linspace(0,3)\n",
    "    t=np.zeros((len(x), 2))\n",
    "    t[:, 1] = x\n",
    "    t[:,0] = t0    \n",
    "\n",
    "    fig, ax = plt.subplots(1, 4)\n",
    "\n",
    "    t=np.linspace(tmin, tmax, 4)\n",
    "    x = np.linspace(xmin, xmax, 40)\n",
    "\n",
    "    concat = np.zeros((len(x),2))\n",
    "    concat[:, 1] = x\n",
    "\n",
    "    def plot(i,t):\n",
    "        concat[:,0]= t\n",
    "        ax[i].plot(x, mlp(concat), color=\"red\", label=f\"Tiempo={t}\")\n",
    "        ax[i].plot(x, exact_sol(concat), color =\"green\", label=f\"Tiempo={t}\")\n",
    "        \n",
    "\n",
    "    for i in range(4):\n",
    "        plot(i, t[i])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    mlp.summary()\n",
    "\n",
    "model_summary(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
